{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Expression analysis\n",
    "\n",
    "## About this lab\n",
    "\n",
    "On this lab, we will try to understand the underlying mechanisms and concepts behind differential expression analysis a multiple hypothesis testing. You will be asked to reflect on some core concepts of the methods and to write down your interpretations. It is important that you understand what you are doing, so thoughtful answers are expected.\n",
    "\n",
    "To successfully complete the lab you have to answer all questions and submit them in **PDF format** in Canvas. You can, and should, discuss with your classmates.\n",
    "\n",
    "You will also be provided with some optional bonus questions that involve a little more research and programming on your part, but successful completion of those will award you points in the final examination.\n",
    "\n",
    "Let's begin! As in every notebook, we first begin by importing packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interact_manual\n",
    "from ipywidgets import IntSlider, FloatSlider, Dropdown, Text\n",
    "\n",
    "interact_gen=interact_manual.options(manual_name=\"Generate data\")\n",
    "interact_plot=interact_manual.options(manual_name=\"Plot\")\n",
    "interact_calc=interact_manual.options(manual_name=\"Calculate tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Differential expression analysis, an intuition\n",
    "\n",
    "As you have learned, differential expression analysis tries to answer the following question: Is there any **significant** difference between the expression of two (or more) different conditions?\n",
    "\n",
    "Throughout this lab we will be exploring the concepts using simulated data, which allows us to finely control what we are looking at and most importantly, know the true model behind the data. Later you will be asked to explore these concepts using real life data, on which you will have to look for the effects without knowing if there is really one.\n",
    "\n",
    "Our simulated data is very basic, and corresponds to two separately generated sets.\n",
    "On the first the data is generated by **two separate** normal distributions, with the data points colored according to which distribution they are generated from.\n",
    "On the second set, the data is generated by a **single** normal distribution, but with the same mean and standard deviation as the combined distribution from the previous set, and where the points are colored at random.\n",
    "\n",
    "In the language of differential expression, the colors represent the different conditions we want to test (e.g. treated/untreated, healthy/sick, etc.).\n",
    "The second data set then represents our **null hypothesis** $H_0$, that says that there is no difference between the \"expression\" of the two conditions.\n",
    "Finally, the first set then represents the **alternative hypothesis** $H_1$ that says that *there is* a difference between the two conditions.\n",
    "\n",
    "I hope the explanation of this was clear, but in case you have any questions, please ask the TA as this is fundamental for the rest of the exercise.\n",
    "\n",
    "Ok, let's try to get an intuition on differential expression fist. After executing the code below you will be presented with 2 plots and some sliders.\n",
    "The sliders control the parameters used for generating the samples from the two different sets, and plot the results.\n",
    "The catch here is that you do not know which plot represents data under $H_0$ and which represents data under $H_1$.\n",
    "Every time you move one of the sliders, the data is regenerated, and each of the condition is **plotted randomly in the left or right panes**.\n",
    "\n",
    "Play around with the sliders as long as you feel necessary to answer these questions.\n",
    "An explanation of what the slides control:\n",
    "* Distance: the difference between the mean of each distribution in $H_1$\n",
    "* Dispersion: the standard deviation $\\sigma$ of those distributions\n",
    "* Samples: The number of samples from each distribuition.\n",
    "\n",
    "### Questions\n",
    "* 1.1 What is the influence of **each** variable in your ability to distinguish between $H_0$ and $H_1$?\n",
    "* 1.2 How do the different variables interact with themselves? (also where it relates to your ability to distinguish the distributions)\n",
    "* 1.3 It is easy to see that often data under $H_1$ looks like data under $H_0$, but do you think you could ever misidentify data under $H_0$ as data under $H_1$?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(distance,dispersion, n_points):\n",
    "    dispersion = [[dispersion,0],[0,dispersion]]\n",
    "    cond1 = np.random.multivariate_normal([0,0], dispersion, n_points)\n",
    "    cond2 = np.random.multivariate_normal([distance,0], dispersion, n_points)\n",
    "    data1 = pd.DataFrame(cond1, columns=['x','y'])\n",
    "    data1['Condition'] = 1\n",
    "    data2 = pd.DataFrame(cond2, columns=['x','y'])\n",
    "    data2['Condition'] = 2\n",
    "    data = pd.concat([data1,data2])\n",
    "    return data\n",
    "\n",
    "def generate_h0(distance,dispersion, n_points):\n",
    "    dispersion = [[dispersion + (distance/2)**2,0],[0,dispersion]]\n",
    "    cond1 = np.random.multivariate_normal([distance/2,0], dispersion, n_points)\n",
    "    cond2 = np.random.multivariate_normal([distance/2,0], dispersion, n_points)\n",
    "    data1 = pd.DataFrame(cond1, columns=['x','y'])\n",
    "    data1['Condition'] = 1\n",
    "    data2 = pd.DataFrame(cond2, columns=['x','y'])\n",
    "    data2['Condition'] = 2\n",
    "    data = pd.concat([data1,data2])\n",
    "    return data\n",
    "\n",
    "def plot_random(data,data_s):\n",
    "    f, ax = plt.subplots(1, 2)\n",
    "    r1 = np.random.permutation(2)\n",
    "    colors = np.random.permutation(['red','blue']).tolist()\n",
    "    sns.scatterplot(x='x', y='y', data=data, hue = 'Condition', palette=colors, ax = ax[r1[0]], legend  = False)\n",
    "    sns.scatterplot(x='x', y='y', data=data_s, hue = 'Condition', palette=colors, ax = ax[r1[1]], legend = False)\n",
    "\n",
    "def dist_plot(Distance,Dispersion,Samples):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    data = generate_data(Distance,Dispersion, Samples)\n",
    "    data_s = generate_h0(Distance,Dispersion, Samples)\n",
    "    plot_random(data,data_s)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(dist_plot, Distance = FloatSlider(min=0,max=10,value=1, continuous_update=False), Dispersion = FloatSlider(min=0,max=100,value=1, continuous_update=False), Samples=IntSlider(min=5,max=500, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 The t-test\n",
    "\n",
    "Now that you have a feel for what differential expression tries to achieve, and some obstacles on the way of doing that, lets introduce a statistical test to help us.\n",
    "We will use the **t-test**, which will give us p-value to assist us in answering the question.\n",
    "\n",
    "(As a technicality, you may have realized that the samples only differ on the $x$ axis, so we are only performing the test on that dimension)\n",
    "\n",
    "The setup here is nearly the same as above, just now you will be presented with the p-value resulting from the t-test as the title for each plot (rounded to 5 digits). Again, you should play around with the sliders and answer the following questions:\n",
    "\n",
    "### Questions\n",
    "* 2.1 Look up the Student's t-test on your favourite online encyclopedia. What are the assumptions this test makes about the data? Do this assumptions hold here?\n",
    "* 2.2 The t-test gives us a p-value. How do you interpret this value on this setup?\n",
    "* 2.3 Does the p-value confirm your intuitions from the previous part? How would you augment your previous answers (1.1 - 1.3) on that light?\n",
    "* 2.4 Our initial question was \"is there any significant difference between the two cases\". As an answer, it is usual to reject $H_0$ for p-values lower than 0.05. Pick a very small distance between both distributions and see if you could make it significant using the other sliders, specially the sample size, and then comment on the relations of statistical significance and biological significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_ttest(data,data_s):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    cond1 = data[data['Condition'] == 1]\n",
    "    cond2 = data[data['Condition'] == 2]\n",
    "    cond1_s = data_s[data_s['Condition'] == 1]\n",
    "    cond2_s = data_s[data_s['Condition'] == 2]\n",
    "    ttestp = sp.stats.ttest_ind(cond1, cond2).pvalue[0]\n",
    "    ttestp_s= sp.stats.ttest_ind(cond1_s, cond2_s).pvalue[0]\n",
    "    f, ax = plt.subplots(1, 2)\n",
    "    r1 = np.random.permutation(2)\n",
    "    colors = np.random.permutation(['red','blue']).tolist()\n",
    "    sns.scatterplot(x='x', y='y', data=data, hue = 'Condition', palette=colors, ax = ax[r1[0]], legend  = False)\n",
    "    ax[r1[0]].set_title('p = ' + str(ttestp), fontsize=24)\n",
    "    sns.scatterplot(x='x', y='y', data=data_s, hue = 'Condition', palette=colors, ax = ax[r1[1]], legend = False)\n",
    "    ax[r1[1]].set_title('p = ' + str(ttestp_s), fontsize=24)\n",
    "    \n",
    "\n",
    "def dist_plot_ttest(Distance,Dispersion,Samples):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    data = generate_data(Distance,Dispersion, Samples)\n",
    "    data_s = generate_h0(Distance,Dispersion, Samples)\n",
    "    plot_random_ttest(data,data_s)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(dist_plot_ttest, Distance = FloatSlider(min=0,max=10,value=1, continuous_update=False), Dispersion = FloatSlider(min=0,max=100,value=1, continuous_update=False), Samples=IntSlider(min=5,max=500, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise, differential gene expression analysis with TCGA data\n",
    "\n",
    "Now it is time to test all this with real data. Below we will load TCGA data on breast cancer, both clinical and gene expression data taken from the tumours.\n",
    "\n",
    "The code below loads the files data and plots the result (including p-value from the t-test). All you need to do is input the name of the gene you want to test (using HUGO nomenclature), as well how you want to separate the groups of patients.\n",
    "\n",
    "To find valid separations, you will have to look at the original file *data_clinical_patient.txt*. Remember that the input has to be exactly present in the file, and is case-sensitive.\n",
    "\n",
    "Questions:\n",
    "* 2.5 Is gene expression data compatible with the assumptions of the t-test? If not, how to go around it?\n",
    "* 2.6 Look at the clinical data file (data_clinical_sample.txt) using an application of your choice (e.g. Excel, LibreOffice, etc) and select a few clinical conditions that you think will affect gene expression. Comment on the number of samples.\n",
    "* 2.7 Perform the test on some (at least 5) genes that you know the function of, use **relevant** clinical conditions to separate the groups, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data = pd.read_csv('../data/brca_clin.tsv.gz', sep ='\\t', index_col=2)\n",
    "clinical_data = clinical_data.iloc[4:,1:]\n",
    "expression_data = pd.read_csv('../data/brca.tsv.gz', sep ='\\t', index_col=1)\n",
    "expression_data = expression_data.iloc[:,2:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_ttest(clinical_df, expression_df, gene, separator, cond1, cond2):\n",
    "    try:\n",
    "        expression = expression_df[gene]\n",
    "    except:\n",
    "        print('ERROR: Gene not found in data')\n",
    "    try:\n",
    "        group1 = clinical_df[separator] == cond1\n",
    "        index1 = clinical_df[group1].index\n",
    "        group2 = clinical_df[separator] == cond2\n",
    "        index2 = clinical_df[group2].index\n",
    "    except:\n",
    "        print('ERROR: Clinical condition wrong')\n",
    "    expression1 = expression[index1].dropna()\n",
    "    expression2 = expression[index2].dropna()\n",
    "    cond = np.append(np.repeat('Group_1',len(expression1)),(np.repeat('Group_2',len(expression2))))\n",
    "    comb_expression = np.append(expression1.values, expression2.values)\n",
    "    plot_data = pd.DataFrame([comb_expression,cond]).T\n",
    "    plot_data.columns = ['Expression', 'Condition']\n",
    "    plot_data['Expression'] = plot_data['Expression'].astype(float)\n",
    "    p_val = sp.stats.ttest_ind(expression1, expression2).pvalue\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    sns.set(font_scale=2)\n",
    "    sns.boxplot(x='Expression', y='Condition', data=plot_data)\n",
    "    plt.title(\"p = \" + str(p_val))\n",
    "\n",
    "\n",
    "def interact_gene_ttest(Gene, Criteria, Group_1, Group_2):\n",
    "    gene_ttest(clinical_data, expression_data, Gene, Criteria, Group_1, Group_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_plot(interact_gene_ttest, Gene = Text('BRCA1'), Criteria=Text('Surgical procedure first'), Group_1 = Text('Simple Mastectomy'), Group_2=Text('Lumpectomy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Multiple hypothesis testing\n",
    "\n",
    "So far we have been asking the question for each gene and answering it with a p-value from our statistical test.\n",
    "However, with the rich datasets generated from high-throughput experiments, we usually want to ask several different question, and we thus move to the world of multiple hypothesis testing, where the p-value is loses some of its usefulness because it leads to high **family-wise error rate**.\n",
    "\n",
    "We will here use the same data generation scheme as before, but done many times over for each $H_0$ and $H_1$. This takes much more time, so you will have the option of generating the data once and visualizing it in multiple ways.\n",
    "\n",
    "A good way visualizing how a statistical test behaves with multiple hypothesis is to visualize the distribution of the p-values it generates, and we will explore why in the questions below.\n",
    "\n",
    "Below you will be able to generate data and visualize it using a histogram. Play around with it a while, use your best discretion on how many bins to use for the histogram, and answer the questions below.\n",
    "**Obs:** if you regenerate data, the plot will not automatically redraw, and will only do so when you change one of the sliders.\n",
    "\n",
    "New sliders:\n",
    "* Tests: the number of times the data is generated and the t-test performed under each $H$\n",
    "* Bins: the number of bins in the histogram.\n",
    "\n",
    "## Questions\n",
    "* 3.1 When we say \"multiple hypothesis\", which are the hypothesis we are referring to?\n",
    "* 3.2 Explain with your own words how we can have high **family-wise error rate** even when using very strict p-values.\n",
    "* 3.3 Do you think it is easier to identify $H_0$ and $H_1$ in this setup? Why do you think that is the case?\n",
    "* 3.4 Comment on the distribution of p-values under $H_0$, its shape and how it changes from different realizations and how each parameter affects the distribution.\n",
    "* 3.5 Take one realization of your data under $H_0$ and roughly count how many p-values under 0.05 you have. Is this expected? Comment also in context of your answer to question 1.3.\n",
    "* 3.6 Comment on the distribution of p-values under $H_1$, its shape and how it changes from different realizations and how each parameter affects the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_tests(distance, dispersion, n_points, n_tests_h0, n_tests_h1):\n",
    "    h0_stats = []\n",
    "    for i in range(n_tests_h0):\n",
    "        data_h0 = generate_h0(distance,dispersion, n_points)\n",
    "        cond1_s = data_h0[data_h0['Condition'] == 1]\n",
    "        cond2_s = data_h0[data_h0['Condition'] == 2]\n",
    "        ttestp_s= sp.stats.ttest_ind(cond1_s, cond2_s).pvalue[0]\n",
    "        h0_stats.append(ttestp_s)\n",
    "\n",
    "    h1_stats = []\n",
    "    for i in range(n_tests_h1):\n",
    "        data = generate_data(distance,dispersion, n_points)\n",
    "        cond1 = data[data['Condition'] == 1]\n",
    "        cond2 = data[data['Condition'] == 2]\n",
    "        ttestp = sp.stats.ttest_ind(cond1, cond2).pvalue[0]\n",
    "        h1_stats.append(ttestp)\n",
    "        \n",
    "    return h0_stats, h1_stats\n",
    "\n",
    "def plot_hist(h0_stats, h1_stats, bins):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    f, ax = plt.subplots(1, 2)\n",
    "    sns.distplot(h0_stats, bins = bins, ax = ax[0], kde=False, hist_kws={\"range\": [0,1]})\n",
    "    sns.distplot(h1_stats, bins = bins, ax = ax[1], kde=False, hist_kws={\"range\": [0,1]})\n",
    "    ax[0].set_title('H0')\n",
    "    ax[0].set_xlim([0,1])\n",
    "    ax[1].set_title('H1')\n",
    "    ax[1].set_xlim([0,1])\n",
    "    plt.show()\n",
    "    \n",
    "def interactive_generate(Distance, Dispersion, Samples, Tests):\n",
    "    global G_h0_results, G_h1_results\n",
    "    G_h0_results, G_h1_results = multiple_tests(Distance,Dispersion, Samples, Tests, Tests)\n",
    "    \n",
    "def interactive_double_hist(Bins):\n",
    "    plot_hist(G_h0_results, G_h1_results, Bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interactive_generate(1, 1, 3, 100)\n",
    "interact_gen(interactive_generate, Distance = FloatSlider(min=0.0,max=10.0,value=1), Dispersion = FloatSlider(min=1.0,max=100.0,value=1), Samples = IntSlider(min=5,max=100), Tests = IntSlider(min=5,max=1000,value=100))\n",
    "interact_plot(interactive_double_hist, Bins=IntSlider(min=10,max=50, step = 10, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Calculating FDR\n",
    "\n",
    "While we can, in this context, analyse both the data generated under $H_0$ and $H_1$ separately, in reality they are often mixed together, and we use the statistical test precisely to **tell if the data comes from $H_0$ or not**.\n",
    "\n",
    "As you have seen in the exercises above, given enough tests, you will almost always have instances where you reject the null hypothesis when it is true no matter which threshold of significance you choose. In this context, we call these errors **false discoveries**.\n",
    "The false discovery rate (FDR), then, is the rate on which these errors occur.\n",
    "\n",
    "On the next plot, you will see a **stacked histogram** on the left, showing the distribution of p-values of both $H$ visualized together, and you will see a red vertical line that shows your significance threshold (left of the line = significant).\n",
    "On the right you have all the p-values ranker from the lowest on the top-left corner to the highest on the lower-right, and coloured by which $H$ it originated from, with the shaded area representing those below the threshold.\n",
    "\n",
    "By moving the threshold slider, you will select on which tests you will reject the null, or in the context of differential expression, the data you believe to be *expressed differentially* between conditions, and that will contain data that is both **truly not coming from $H_0$** and those that were **incorrectly rejected**.\n",
    "\n",
    "In our very special case here, we know from before which data comes from $H_0$ and from $H_1$, so we can calculate the FDR exactly, and that will be shown on top of the pane on the right.\n",
    "\n",
    "New sliders:\n",
    "* H_ratio: the ratio of tests performed under each $H$, calculated as $H_0/H_1$\n",
    "* Threshold: p-value threshold for rejecting $H_0$\n",
    "\n",
    "### Questions\n",
    "\n",
    "* 4.1 What relations do you see between the FDR and each of the sliders. You may refer to the answers you gave on previous questions if you wish.\n",
    "* 4.2 How does the FDR relate to the shape of the distribution of p-values of $H_0$ and $H_1$?\n",
    "* 4.3 It is usual to think that a lower p-value threshold will lead to a lower FDR. Is this always true?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_comb(h0_stats, h1_stats, bins, threshold):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    f, ax = plt.subplots(1, 2)\n",
    "    ax[0].hist([h0_stats, h1_stats], bins = bins, stacked = True)\n",
    "    ax[0].vlines(threshold, 0, ax[0].get_ylim()[1], color='r', linestyles = 'dashed')\n",
    "    stats = pd.DataFrame(h1_stats + h0_stats, columns = ['p'])\n",
    "    stats['h'] = np.repeat(1,len(h1_stats)).tolist() + np.repeat(0,len(h0_stats)).tolist()\n",
    "    stats['good'] = (stats['p'] <= threshold)*1\n",
    "    discoveries = stats.loc[stats['p'] <= threshold]\n",
    "    fdr_true = 1 - sum(discoveries['h'])/len(discoveries['h'])\n",
    "    stats = stats.sort_values('p')\n",
    "    stack1 = stats['h']\n",
    "    stack2 = stats['good']\n",
    "    side = np.ceil(np.sqrt(len(stack1))).astype(int)\n",
    "    pad1 = np.zeros(side*side)+9\n",
    "    pad2 = np.zeros(side*side)+9\n",
    "    pad1[:len(stack1)]=stack1\n",
    "    pad2[:len(stack1)]=stack2 * 5\n",
    "    ax[1].imshow(pad1.reshape(side,side), cmap = 'Set1')\n",
    "    ax[1].imshow(pad2.reshape(side,side), cmap = 'Set1', alpha = 0.4)\n",
    "    ax[1].set_title('FDR: ' + str(np.round(fdr_true, 3)), fontsize=24)\n",
    "    plt.show()\n",
    "    \n",
    "def interactive_generate_n(Distance, Dispersion, Samples, Tests, H_Ratio):\n",
    "    global G_h0_results_n, G_h1_results_n\n",
    "    r = H_Ratio\n",
    "    n_tests_h0 = np.round(r*Tests*2).astype(int)\n",
    "    n_tests_h1 = np.round((1-r)*Tests*2).astype(int)\n",
    "    G_h0_results_n, G_h1_results_n = multiple_tests(Distance,Dispersion, Samples, n_tests_h0, n_tests_h1)\n",
    "\n",
    "def interactive_plot_hist_comb(Bins, Threshold):\n",
    "    plot_hist_comb(G_h0_results_n, G_h1_results_n, Bins, Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_generate_n(1, 10, 30, 100, 0.5)\n",
    "interact_gen(interactive_generate_n, Distance = FloatSlider(min=0.0,max=10.0,value=1), Dispersion = FloatSlider(min=0.0,max=100.0,value=1), Samples = IntSlider(min=5,max=100), Tests = IntSlider(min=5,max=1000,value=100), H_Ratio = FloatSlider(min=0,max=1, step = 0.01, value = 0.5, continuous_update=False))\n",
    "interact_plot(interactive_plot_hist_comb, Threshold = FloatSlider(min=0,max=0.5, step = 0.01,value=0.05, continuous_update=False), Bins=IntSlider(min=10,max=100, value=20, step = 10, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Estimating the FDR, using $\\pi_0$\n",
    "\n",
    "You probably realized by now that the p-values under $H_0$ follow a uniform distribution. This comes from the very definition of p-values itself (!), more on why on the bonus exercise. Therefore a very good way to see if your statistical test isn't testing for the wrong thing, is to see if the distribution of p-values from that test under $H_0$ follows those characteristics.\n",
    "\n",
    "Knowing that fact, if we know the number of hypothesis coming from $H_0$, we can estimate the FDR very accurately. Unfortunately, that is never the case, and we have to also estimate this number.\n",
    "We do so by estimating the proportion of data under $H_0$ from the total number of test we made, and we call this proportion $\\pi_0$.\n",
    "\n",
    "Below, you will have the chance to estimate $\\pi_0$ and then see if your estimation is correct.\n",
    "Every time you generate new data, the true $\\pi_0$ will be selected at random from the range $[0,1]$.\n",
    "See if you can find a good way to estimate it, and then answer some questions.\n",
    "\n",
    "New sliders:\n",
    "* Pi0: Your estimative for $\\pi_0$, used to estimate the FDR\n",
    "* Separate: Separate or not $H_0$ and $H_1$ by color\n",
    "\n",
    "## Questions\n",
    "* 5.1 Describe two ways you came with to estimate $\\pi_0$, when it works and when it doesn't work.\n",
    "* 5.2 Is it easier to estimate low or high $\\pi_0$? Why?\n",
    "* 5.3 What does it mean to set $\\pi_0$ to 1. Can we do this and still get reasonable results? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_hist_pi0(h0_stats, h1_stats, bins, threshold, pi0, sep):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    stats = pd.DataFrame(h1_stats + h0_stats, columns = ['p'])\n",
    "    stats['h'] = np.repeat(1,len(h1_stats)).tolist() + np.repeat(0,len(h0_stats)).tolist()\n",
    "    stats = stats.loc[stats['p'] <= threshold]\n",
    "    fdr_true = 1 - sum(stats['h'])/len(stats['h'])\n",
    "    m = len(h0_stats + h1_stats)\n",
    "    fdr_est = min((pi0*m*threshold)/len(stats['h']),1)\n",
    "    h = pi0*m/bins\n",
    "    if sep:\n",
    "        plt.hist([h0_stats, h1_stats], bins = bins, stacked = True, color = ['tab:blue', 'tab:orange'])\n",
    "        plt.title('Estimated FDR: ' + str(np.round(fdr_est, 3)) + ',   True FDR: ' + str(np.round(fdr_true, 3)), fontsize=24)\n",
    "    else:\n",
    "        plt.hist([h0_stats, h1_stats], bins = bins, stacked = True, color = ['tab:blue', 'tab:blue'])\n",
    "        plt.title('Estimated FDR: ' + str(np.round(fdr_est, 3)), fontsize=24)\n",
    "    plt.vlines(threshold, 0, plt.gca().get_ylim()[1], color='r', linestyles = 'dashed')\n",
    "    plt.hlines(h, 0, 1, color='black', linestyles = 'dashed', linewidth=3)\n",
    "    plt.show()\n",
    "    \n",
    "def interactive_plot_hist_pi0(Bins, Threshold, Pi0, Separate):\n",
    "    plot_hist_pi0(G_h0_results_pi0, G_h1_results_pi0, Bins, Threshold, Pi0, Separate)\n",
    "    \n",
    "def interactive_generate_n_rand(Distance, Dispersion, Samples, Tests):\n",
    "    global G_h0_results_pi0, G_h1_results_pi0\n",
    "    r = np.random.uniform(0,1)\n",
    "    n_tests_h0 = np.round(r*Tests*2).astype(int)\n",
    "    n_tests_h1 = np.round((1-r)*Tests*2).astype(int)\n",
    "    G_h0_results_pi0, G_h1_results_pi0 = multiple_tests(Distance,Dispersion, Samples, n_tests_h0, n_tests_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_generate_n_rand(1, 10, 30, 100)\n",
    "interact_gen(interactive_generate_n_rand, Distance = FloatSlider(min=0.0,max=10.0,value=1), Dispersion = FloatSlider(min=0.0,max=100.0,value=1), Samples = IntSlider(min=5,max=100,value=10), Tests = IntSlider(min=5,max=1000,value=100))\n",
    "interact_plot(interactive_plot_hist_pi0, Threshold = FloatSlider(min=0.01,max=0.5,value=0.05, step = 0.01, continuous_update=False), Bins=IntSlider(min=10,max=100, step = 10,value=20, continuous_update=False), Pi0 = FloatSlider(min=0,max=1, step = 0.01, continuous_update=False), Separate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple hypothesis on TCGA data\n",
    "\n",
    "Now all that is left to do the multiple hypothesis testing on our data. Here you will be able to choose two clinical groups and test all the genes for differential expression on those two groups.\n",
    "\n",
    "* 5.4 Using relevant clinical conditions (at least 5), perform the multiple tests.\n",
    "Report the resulting histograms and the estimated $\\pi_0$, and give your interpretation of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_gene_ttest(clinical_df, expression_df, separator, cond1, cond2):\n",
    "    p_vec = []\n",
    "    try:\n",
    "        group1 = clinical_df[separator] == cond1\n",
    "        index1 = clinical_df[group1].index\n",
    "        group2 = clinical_df[separator] == cond2\n",
    "        index2 = clinical_df[group2].index\n",
    "    except:\n",
    "        print('Clinical condition wrong')\n",
    "    for gene in expression_df.columns:\n",
    "        try:\n",
    "            expression = expression_df[gene]\n",
    "        except:\n",
    "            print('Gene not found in data')\n",
    "        expression1 = expression[index1].dropna()\n",
    "        expression2 = expression[index2].dropna()\n",
    "        p_val = sp.stats.ttest_ind(expression1, expression2).pvalue\n",
    "        p_vec.append(p_val)\n",
    "    return p_vec\n",
    "\n",
    "def plot_hist_pi0_TCGA(stats, bins, threshold, pi0):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    stats = np.array(stats)\n",
    "    stats_accepted = stats[stats <= threshold]\n",
    "    m = len(stats)\n",
    "    fdr_est = min((pi0*m*threshold)/len(stats_accepted),1)\n",
    "    h = pi0*m/bins\n",
    "    plt.hist(stats, bins = bins)\n",
    "    plt.title('Estimated FDR: ' + str(np.round(fdr_est, 3)), fontsize=24)\n",
    "    plt.vlines(threshold, 0, plt.gca().get_ylim()[1], color='r', linestyles = 'dashed')\n",
    "    plt.hlines(h, 0, 1, color='black', linestyles = 'dashed', linewidth=3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def interact_multiple_gene_ttest(Criteria, Group_1, Group_2):\n",
    "    global TCGA_multiple_t\n",
    "    TCGA_multiple_t = multiple_gene_ttest(clinical_data, expression_data, Criteria, Group_1, Group_2)\n",
    "    \n",
    "def interactive_plot_hist_TCGA(Bins, Threshold, Pi0):\n",
    "    plot_hist_pi0_TCGA(TCGA_multiple_t, Bins, Threshold, Pi0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_calc(interact_multiple_gene_ttest, Criteria=Text('Surgical procedure first'), Group_1 = Text('Simple Mastectomy'), Group_2=Text('Lumpectomy'))\n",
    "interact_plot(interactive_plot_hist_TCGA, Threshold = FloatSlider(min=0.01,max=0.5,value=0.05, step = 0.01, continuous_update=False), Bins=IntSlider(min=10,max=100, step = 10,value=20, continuous_update=False), Pi0 = FloatSlider(min=0,max=1, step = 0.01, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus exercises\n",
    "\n",
    "## P-value in depth\n",
    "* Start from the definition of p-value and prove that it's distribution should be uniform under $H_0$.\n",
    "\n",
    "Use the part of the code in this notebook that generated data from two distributions, but after the data is generated, reassign the conditions at random, so that the conditions are no longer associated with each of the distributions.\n",
    "* You will do this multiple times and perform a t-test on the conditions as before, but before doing that, how do you think the distribution of p-values will be? Why?\n",
    "* Perform the t-test for a suitable number of times in different iterations of the data, and show it's distribution.\n",
    "* Does it confirm what you expected? If not, what do you think happened?\n",
    "* Given the answer to your first question, how would you go around this?\n",
    "\n",
    "## Anova\n",
    "\n",
    "* Explain using your own words how statistical significance is derived in an ANOVA test.\n",
    "* Give some examples of when an ANOVA test is proffered over a t-test, as well as when it is not.\n",
    "\n",
    "Substitute the t-test for an ANOVA test on both exercises that make use of the TCGA data. You can use any implementation of the ANOVA test like the one in [Statsmodels package](https://www.statsmodels.org/stable/index.html)\n",
    "* Explain the linear model you used on the ANOVA\n",
    "* Comment on how the results did or did not change, and make hypothesis on **why** it is so.\n",
    "\n",
    "## Volcano plot\n",
    "Make a [volcano plot](https://en.wikipedia.org/wiki/Volcano_plot_(statistics)) derived from a test on all the genes on the TCGA Breast cancer dataset used in this notebook.\n",
    "Explain how you built it, what the plot represents, and interpret it in its context and given all the knowledge you have of the test.\n",
    "\n",
    "## $\\pi_0$ estimation from *Storey et al*\n",
    "\n",
    "* Read through [Storey et al](https://www.pnas.org/content/100/16/9440) and it's references if needed.\n",
    "* Explain in your own words, their proposed algorithm for estimating $\\pi_0$.\n",
    "* Explain why the parameter $\\lambda$ is important and the optimal way of choosing it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
